{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf75791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b89388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('D:\\Hamoye\\Data_for_UCI_named.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b1015d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1933dfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6032ef7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250001</td>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249997</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.015731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.742548</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742556</td>\n",
       "      <td>0.752160</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.500141</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.500473</td>\n",
       "      <td>1.582590</td>\n",
       "      <td>-1.999891</td>\n",
       "      <td>-1.999945</td>\n",
       "      <td>-1.999926</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050053</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.080760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.874892</td>\n",
       "      <td>2.875140</td>\n",
       "      <td>2.875522</td>\n",
       "      <td>2.874950</td>\n",
       "      <td>3.218300</td>\n",
       "      <td>-1.624901</td>\n",
       "      <td>-1.625025</td>\n",
       "      <td>-1.624960</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>0.287552</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.287494</td>\n",
       "      <td>-0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249981</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>5.249734</td>\n",
       "      <td>3.751025</td>\n",
       "      <td>-1.249966</td>\n",
       "      <td>-1.249974</td>\n",
       "      <td>-1.250007</td>\n",
       "      <td>0.525009</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.525002</td>\n",
       "      <td>0.017142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.624690</td>\n",
       "      <td>7.624893</td>\n",
       "      <td>7.624948</td>\n",
       "      <td>7.624838</td>\n",
       "      <td>4.282420</td>\n",
       "      <td>-0.874977</td>\n",
       "      <td>-0.875043</td>\n",
       "      <td>-0.875065</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>0.762490</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.762433</td>\n",
       "      <td>0.044878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999469</td>\n",
       "      <td>9.999837</td>\n",
       "      <td>9.999450</td>\n",
       "      <td>9.999443</td>\n",
       "      <td>5.864418</td>\n",
       "      <td>-0.500108</td>\n",
       "      <td>-0.500072</td>\n",
       "      <td>-0.500025</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.109403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tau1          tau2          tau3          tau4            p1  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       5.250000      5.250001      5.250004      5.249997      3.750000   \n",
       "std        2.742548      2.742549      2.742549      2.742556      0.752160   \n",
       "min        0.500793      0.500141      0.500788      0.500473      1.582590   \n",
       "25%        2.874892      2.875140      2.875522      2.874950      3.218300   \n",
       "50%        5.250004      5.249981      5.249979      5.249734      3.751025   \n",
       "75%        7.624690      7.624893      7.624948      7.624838      4.282420   \n",
       "max        9.999469      9.999837      9.999450      9.999443      5.864418   \n",
       "\n",
       "                 p2            p3            p4            g1            g2  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -1.250000     -1.250000     -1.250000      0.525000      0.525000   \n",
       "std        0.433035      0.433035      0.433035      0.274256      0.274255   \n",
       "min       -1.999891     -1.999945     -1.999926      0.050009      0.050053   \n",
       "25%       -1.624901     -1.625025     -1.624960      0.287521      0.287552   \n",
       "50%       -1.249966     -1.249974     -1.250007      0.525009      0.525003   \n",
       "75%       -0.874977     -0.875043     -0.875065      0.762435      0.762490   \n",
       "max       -0.500108     -0.500072     -0.500025      0.999937      0.999944   \n",
       "\n",
       "                 g3            g4          stab  \n",
       "count  10000.000000  10000.000000  10000.000000  \n",
       "mean       0.525000      0.525000      0.015731  \n",
       "std        0.274255      0.274255      0.036919  \n",
       "min        0.050054      0.050028     -0.080760  \n",
       "25%        0.287514      0.287494     -0.015557  \n",
       "50%        0.525015      0.525002      0.017142  \n",
       "75%        0.762440      0.762433      0.044878  \n",
       "max        0.999982      0.999930      0.109403  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a91d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features= df.drop(['stab','stabf'],axis=1)\n",
    "target= df['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63cb1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(features, target, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a52c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e567b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train)\n",
    "#returns\n",
    "LogisticRegression(C= 1.0 , class_weight= None , dual= False , fit_intercept= True ,\n",
    " intercept_scaling= 1 , l1_ratio= None , max_iter= 100 ,\n",
    " multi_class= 'auto' , n_jobs= None , penalty= 'l2' ,\n",
    " random_state= None , solver= 'lbfgs' , tol= 0.0001 , verbose= 0 ,\n",
    " warm_start= False ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaa8e01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1114,  174],\n",
       "       [ 218,  494]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = log_reg.predict(x_test)\n",
    "cnf_mat = confusion_matrix(y_true=y_test, y_pred=new_predictions, labels=[ 'unstable' , 'stable' ])\n",
    "cnf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "789ad106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8049015 , 0.80345987, 0.80785034, 0.79645688, 0.7835111 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_reg, x_train, y_train, cv= 5 , scoring= 'f1_macro' )\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4961c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=new_predictions)\n",
    "print( 'Accuracy: {}' .format(round(accuracy* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84b208a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 74\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true=y_test, y_pred=new_predictions, pos_label= 'stable' )\n",
    "print( 'Precision: {}' .format(round(precision* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ec6d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 69\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_true=y_test, y_pred=new_predictions, pos_label= 'stable' )\n",
    "print( 'Recall: {}' .format(round(recall* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93b0b94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 72\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true=y_test, y_pred=new_predictions, pos_label= 'stable' )\n",
    "print( 'F1: {}' .format(round(f1* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9262b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Random Forest Classifier is 0.929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest=RandomForestClassifier(random_state=1)\n",
    "random_forest.fit(x_train,y_train)\n",
    "y_pred_random_test = random_forest.predict(x_test)\n",
    "acc_score = round(accuracy_score(y_test, y_pred_random_test), 4)\n",
    "print(f'Accuracy score of the Random Forest Classifier is {acc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54f1cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ShrutiKirti\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:40:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Accuracy score of the XGB Classifier is 0.9455\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGBmodel=XGBClassifier(random_state=1)\n",
    "XGBmodel.fit(x_train,y_train)\n",
    "y_pred_XGB=XGBmodel.predict(x_test)\n",
    "acc_score = round(accuracy_score(y_test, y_pred_XGB), 4)\n",
    "print(f'\\nAccuracy score of the XGB Classifier is {acc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2424f7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LGBM Classifier is 0.9395\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "LGBMmodel=LGBMClassifier(random_state=1)\n",
    "LGBMmodel.fit(x_train,y_train)\n",
    "y_pred_LGBM=LGBMmodel.predict(x_test)\n",
    "acc_score = round(accuracy_score(y_test, y_pred_LGBM), 4)\n",
    "print(f'Accuracy score of the LGBM Classifier is {acc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3951b1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Extra Trees Classifier is 0.928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "extra_tree_forest = ExtraTreesClassifier(random_state=1)\n",
    "extra_tree_forest.fit(x_train,y_train)\n",
    "y_pred_extratree_test = extra_tree_forest.predict(x_test)\n",
    "acc_score = round(accuracy_score(y_test, y_pred_extratree_test), 4)\n",
    "print(f'Accuracy score of the Extra Trees Classifier is {acc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef1aaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=ExtraTreesClassifier(random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_features': ['auto', 'sqrt', 'log2',\n",
       "                                                         None],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [2, 3, 5, 7, 9],\n",
       "                                        'n_estimators': [50, 100, 300, 500,\n",
       "                                                         1000]},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}\n",
    "extra_classifier = ExtraTreesClassifier(random_state=1)\n",
    "randomised_grid_search = RandomizedSearchCV(extra_classifier, param_distributions= hyperparameter_grid,\n",
    "                                scoring='accuracy',\n",
    "                                n_iter=10,\n",
    "                                cv=5,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=1)\n",
    "randomised_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24a4f414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 7,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomised_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bb81597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old accuracy score is 0.928\n",
      "New Accuracy score is 0.9305\n"
     ]
    }
   ],
   "source": [
    "extra_classifier.fit(x_train, y_train)\n",
    "\n",
    "old_score = round(accuracy_score(y_test, extra_classifier.predict(x_test)), 4)\n",
    "print(f'Old accuracy score is {old_score}')\n",
    "\n",
    "new_model = randomised_grid_search.best_estimator_\n",
    "new_model.fit(x_train, y_train)\n",
    "new_pred = new_model.predict(x_test)\n",
    "\n",
    "new_score= round(accuracy_score(y_test, new_pred), 4)\n",
    "print(f'New Accuracy score is {new_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04cfe636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = new_model.feature_importances_\n",
    "indices = np.argsort(feature_importances)\n",
    "names = [x_train.columns[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.bar(range(x_train.shape[1]), feature_importances[indices])\n",
    "plt.xticks(range(x_train.shape[1]), names, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db2595a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP= 355\n",
    "TN= 120\n",
    "FP= 1480\n",
    "FN= 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0b2d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19346049046321526\n"
     ]
    }
   ],
   "source": [
    "Precision= TP/(TP+FP)\n",
    "print(Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56b45c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8875\n"
     ]
    }
   ],
   "source": [
    "Recall= TP/(TP+FN)\n",
    "print(Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "490237de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3176733780760626\n"
     ]
    }
   ],
   "source": [
    "F1 = (Precision*Recall)/(Precision+Recall)\n",
    "F1_score= F1*2\n",
    "print(F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbc33361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall option A is 0.82\n",
      "False Positive Rate option A is 0.0392156862745098\n",
      "Costs option A is 560 \n",
      "\n",
      "Recall option B is 0.7777777777777778\n",
      "False Positive Rate option B is 0.27\n",
      "Costs option B is 1700 \n",
      "\n",
      "Recall option C is 0.9\n",
      "False Positive Rate option C is 0.01\n",
      "Costs option C is 150 \n",
      "\n",
      "Recall option D is 0.78\n",
      "False Positive Rate option D is 0.09\n",
      "Costs option D is 670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# computing for option A\n",
    "print(f'Recall option A is {820 / (820 + 180)}')\n",
    "print(f'False Positive Rate option A is {40 / (40 + 980)}')\n",
    "print(f'Costs option A is {5 * 40 + 360} \\n')\n",
    "\n",
    "# computing for option B\n",
    "print(f'Recall option B is {700 / (700 + 200)}')\n",
    "print(f'False Positive Rate option B is {round(300 / (300 + 800), 2)}')\n",
    "print(f'Costs option B is {5 * 300 + 200} \\n')\n",
    "\n",
    "# computing for option C\n",
    "print(f'Recall option C is {900/ (900 + 100)}')\n",
    "print(f'False Positive Rate option C is {10 / (10 + 990)}')\n",
    "print(f'Costs option C is {5 * 10 + 100} \\n')\n",
    "\n",
    "# computing for option D\n",
    "print(f'Recall option D is {780 / (780 + 220)}')\n",
    "print(f'False Positive Rate option D is {90 / (90 + 910)}')\n",
    "print(f'Costs option D is {5 * 90 + 220}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9977e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
